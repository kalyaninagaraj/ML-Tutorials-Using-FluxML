{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL 2\n",
    "## Multi-Class Classification Using The Flux.jl Package On MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries: Include packages and user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readclassjson (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra, Random, Statistics, Flux\n",
    "using Flux: crossentropy, onecold, onehotbatch, throttle\n",
    "using Base.Iterators: repeated\n",
    "include(\"myJuliaLib/MNIST.jl\")         # contains function `dispMNISTPatches`\n",
    "include(\"myJuliaLib/readclassjson.jl\") # contains function `readclassjson`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and test data from JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 2 entries:\n",
       "  \"X\" => [0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n",
       "  \"y\" => [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd(@__DIR__)\n",
    "isfile(\"MNIST_train.json\") || MNIST2json()\n",
    "\n",
    "MNIST_train = readclassjson(\"JSON/MNIST_train.json\")\n",
    "MNIST_test  = readclassjson(\"JSON/MNIST_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed data by scaling pixel values to appear on the [0,1] interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. SCALE FEATURES BY 255 SO THAT PIXEL VALUES ARE IN THE RANGE (0,1)\n",
    "x_train = MNIST_train[\"X\"]/255\n",
    "x_test  = MNIST_test[\"X\"]/255\n",
    "\n",
    "# 2. ONE-HOT ENCODE OUTCOMES \n",
    "y_train = MNIST_train[\"y\"];\n",
    "y_test = MNIST_test[\"y\"];\n",
    "Y_train = onehotbatch(y_train, 0:9)\n",
    "Y_test  = onehotbatch(y_test, 0:9);\n",
    "\n",
    "Ntrain, d = size(x_train)\n",
    "Ntest = length(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimension performing Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean the data and perform SVD\n",
    "x_demean = [x_train; x_test] .- mean([x_train; x_test], dims = 1) \n",
    "Ftrain = svd((x_demean' * x_demean) / size(x_demean, 1))\n",
    "lambdas = cumsum(Ftrain.S)/sum(Ftrain.S)     # variance contributed to by first k components, k = 1:d\n",
    "k = searchsortedfirst(lambdas, 0.99)         # find number of components to retain\n",
    "xPCA = x_demean * Ftrain.U[:,1:k];           # reduced dimension representation of training data\n",
    "\n",
    "xPCA_train = xPCA[1:Ntrain, :]\n",
    "xPCA_test  = xPCA[Ntrain+1:Ntrain+Ntest, :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a multi-layer perceptron (that is, a multi-layer neural network) on the reduced-dimension training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(x_train', Y_train) = 0.09961666666666667\n",
      "accuracy(x_test', Y_test) = 0.0968\n",
      "accuracy(x_train', Y_train) = 0.1478\n",
      "accuracy(x_test', Y_test) = 0.1462\n",
      "accuracy(x_train', Y_train) = 0.17653333333333332\n",
      "accuracy(x_test', Y_test) = 0.1767\n",
      "accuracy(x_train', Y_train) = 0.21995\n",
      "accuracy(x_test', Y_test) = 0.2212\n",
      "accuracy(x_train', Y_train) = 0.32588333333333336\n",
      "accuracy(x_test', Y_test) = 0.3248\n",
      "accuracy(x_train', Y_train) = 0.43291666666666667\n",
      "accuracy(x_test', Y_test) = 0.437\n",
      "accuracy(x_train', Y_train) = 0.48086666666666666\n",
      "accuracy(x_test', Y_test) = 0.484\n",
      "accuracy(x_train', Y_train) = 0.5231166666666667\n",
      "accuracy(x_test', Y_test) = 0.5264\n",
      "accuracy(x_train', Y_train) = 0.5514\n",
      "accuracy(x_test', Y_test) = 0.552\n",
      "accuracy(x_train', Y_train) = 0.5728333333333333\n",
      "accuracy(x_test', Y_test) = 0.5699\n",
      "accuracy(x_train', Y_train) = 0.5897333333333333\n",
      "accuracy(x_test', Y_test) = 0.5895\n",
      "accuracy(x_train', Y_train) = 0.6030166666666666\n",
      "accuracy(x_test', Y_test) = 0.6043\n",
      "accuracy(x_train', Y_train) = 0.6151\n",
      "accuracy(x_test', Y_test) = 0.6153\n",
      "accuracy(x_train', Y_train) = 0.6254666666666666\n",
      "accuracy(x_test', Y_test) = 0.6282\n",
      "accuracy(x_train', Y_train) = 0.6343333333333333\n",
      "accuracy(x_test', Y_test) = 0.6382\n",
      "accuracy(x_train', Y_train) = 0.6430333333333333\n",
      "accuracy(x_test', Y_test) = 0.6461\n",
      "accuracy(x_train', Y_train) = 0.6510666666666667\n",
      "accuracy(x_test', Y_test) = 0.654\n",
      "accuracy(x_train', Y_train) = 0.658\n",
      "accuracy(x_test', Y_test) = 0.6611\n",
      "accuracy(x_train', Y_train) = 0.6645666666666666\n",
      "accuracy(x_test', Y_test) = 0.6673\n",
      "accuracy(x_train', Y_train) = 0.6709666666666667\n",
      "accuracy(x_test', Y_test) = 0.674\n",
      "accuracy(x_train', Y_train) = 0.6766166666666666\n",
      "accuracy(x_test', Y_test) = 0.6792\n",
      "accuracy(x_train', Y_train) = 0.6820166666666667\n",
      "accuracy(x_test', Y_test) = 0.684\n",
      "accuracy(x_train', Y_train) = 0.6865666666666667\n",
      "accuracy(x_test', Y_test) = 0.69\n",
      "accuracy(x_train', Y_train) = 0.6914666666666667\n",
      "accuracy(x_test', Y_test) = 0.6945\n",
      "accuracy(x_train', Y_train) = 0.6966166666666667\n",
      "accuracy(x_test', Y_test) = 0.6997\n",
      "accuracy(x_train', Y_train) = 0.7006333333333333\n",
      "accuracy(x_test', Y_test) = 0.7041\n",
      "accuracy(x_train', Y_train) = 0.7049666666666666\n",
      "accuracy(x_test', Y_test) = 0.7096\n",
      "accuracy(x_train', Y_train) = 0.7087\n",
      "accuracy(x_test', Y_test) = 0.7135\n",
      "accuracy(x_train', Y_train) = 0.7130333333333333\n",
      "accuracy(x_test', Y_test) = 0.718\n"
     ]
    }
   ],
   "source": [
    "# Define NN model\n",
    "model = Chain(Dense(d, 32, sigmoid),\n",
    "              Dense(32, 10), softmax)\n",
    "\n",
    "# Define loss function\n",
    "loss(x, y) = crossentropy(model(x), y) \n",
    "\n",
    "# Define optimizer\n",
    "optimiser = Descent(0.1)\n",
    "# optimiser = ADAM()\n",
    "\n",
    "# Create iterator to train model over 110 epochs. \n",
    "# 110 epochs gives a test (and train) accuracy of ~71% \n",
    "# when using gradient descent with lambda = 0.1. \n",
    "# Try going up to 500 epochs, or using other solvers\n",
    "# like ADAM, but this may take a while. \n",
    "dataset = Iterators.repeated((x_train', Y_train), 110)\n",
    "\n",
    "# Call back\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "evalcb() = @show(accuracy(x_train', Y_train), accuracy(x_test', Y_test))\n",
    "\n",
    "# Train model on data set\n",
    "Flux.train!(loss, params(model), dataset, optimiser, cb = throttle(evalcb, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model by applying it on to test data and measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10 Matrix{Int64}:\n",
       " 5616    12    33    84    27     3   101    13    30     4\n",
       "    0  6645    26    38     2     2    14     8     3     4\n",
       "  210   782  4039   294   137     0   234   187    65    10\n",
       "   86   335   168  4877     7    30    65   137   319   107\n",
       "   28   265    27    13  3916     0   101    72     2  1418\n",
       "  623   581    89  1793   313  1056   277   117   329   243\n",
       "  225   257   159   100   155    10  5009     0     2     1\n",
       "  131   417    54    11   159     0    12  5359     2   120\n",
       "  218  1131   134  1100    69    56   113   169  2485   376\n",
       "   98   300    62   122   826     0     7   657    22  3855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10×10 Matrix{Int64}:\n",
       " 936     0    7   14    5    0   14    1    3    0\n",
       "   0  1122    3    5    0    0    4    1    0    0\n",
       "  37   164  660   62   21    1   35   32   20    0\n",
       "   4    38   22  854    1    1    9   25   47    9\n",
       "   2    50    7    2  634    0   24    6    0  257\n",
       "  92    72   11  296   44  200   45   29   61   42\n",
       "  55    27   29   18   33    2  793    1    0    0\n",
       "  12    74   16    0   16    0    2  881    2   25\n",
       "  48   130   17  209   13    6   24   40  423   64\n",
       "  24    38   10   16  137    0    1   86    6  691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate confusion matrix on training and test data\n",
    "function confusion_matrix(X, y)\n",
    "    ŷ = onehotbatch(onecold(model(X)) .- 1, 0:9)\n",
    "    y * ŷ'\n",
    "end\n",
    "display(confusion_matrix(x_train', Y_train))\n",
    "display(confusion_matrix(x_test', Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "144×146 reinterpret(reshape, Gray{Float16}, ::Matrix{Float16}) with eltype Gray{Float16}:\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)  …  Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)  …  Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)  …  Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " ⋮                                       ⋱  ⋮\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)  …  Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)  …  Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)\n",
       " Gray{Float16}(1.0)  Gray{Float16}(0.0)     Gray{Float16}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Int64}:\n",
       " 3  4  6  4  6\n",
       " 2  2  1  3  4\n",
       " 3  1  1  7  8\n",
       " 7  3  2  5  8\n",
       " 2  5  6  4  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 71.42833333333334%\n",
      "Test accuracy = 71.94%\n"
     ]
    }
   ],
   "source": [
    "# Display a patch of randomly chosen images from the test set\n",
    "patchSize = 5\n",
    "randIndx = randperm(MersenneTwister(724629), size(x_test,1))\n",
    "randIndx = randIndx[1:patchSize^2] \n",
    "IM_test  = dispMNISTPatches(x_test[randIndx, :], patchSize)\n",
    "display(IM_test)\n",
    "\n",
    "# Predict outcome for test set\n",
    "yhat_test = onecold(model(x_test')) .- 1\n",
    "display(reshape(y_test[randIndx], patchSize, patchSize))\n",
    "\n",
    "# Print overall accuracy\n",
    "println(\"Training accuracy = \", accuracy(x_train', Y_train)*100, \"%\\nTest accuracy = \", accuracy(x_test', Y_test)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
